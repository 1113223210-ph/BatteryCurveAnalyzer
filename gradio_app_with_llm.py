# gradio_app_with_llm.py
import gradio as gr
import torch
from fastai.vision.all import *
from pathlib import Path
from transformers import AutoModelForCausalLM, AutoTokenizer
import os

# ---------- 1. åŠ è½½ç”µæ± æ›²çº¿åˆ†ç±»å™¨ ----------
print("ğŸ“¸ åŠ è½½åˆ†ç±»å™¨æ¨¡å‹...")
classifier_path = Path('models/curve_classifier_updated.pkl')
# å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•åŠ è½½æ—§ç‰ˆæœ¬
if not classifier_path.exists():
    classifier_path = Path('models/curve_classifier.pkl')
learn = load_learner(classifier_path)
print(f"âœ… åˆ†ç±»å™¨åŠ è½½æˆåŠŸï¼Œç±»åˆ«: {learn.dls.vocab}")

# ---------- 2. åŠ è½½ Qwen è¯­è¨€æ¨¡å‹ ----------
print("ğŸ§  åŠ è½½ Qwen è¯­è¨€æ¨¡å‹...")
# ä½¿ç”¨ä½ åˆšåˆšæˆåŠŸçš„è·¯å¾„ï¼ˆè¯·ç¡®è®¤è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼‰
qwen_path = os.path.expanduser('~/MinivLLM/models/Qwen3-0.6B')

# åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹ï¼ˆä½¿ç”¨ local_files_only=True å¼ºåˆ¶æœ¬åœ°åŠ è½½ï¼‰
tokenizer = AutoTokenizer.from_pretrained(
    qwen_path,
    trust_remote_code=True,
    local_files_only=True
)
model = AutoModelForCausalLM.from_pretrained(
    qwen_path,
    torch_dtype=torch.float16,      # ä½¿ç”¨åŠç²¾åº¦èŠ‚çœæ˜¾å­˜
    device_map='auto',               # è‡ªåŠ¨åˆ†é…åˆ° GPU
    trust_remote_code=True,
    local_files_only=True
)
print("âœ… Qwen æ¨¡å‹åŠ è½½æˆåŠŸï¼")

# ---------- 3. å®šä¹‰é¢„æµ‹å‡½æ•°ï¼ˆåˆ†ç±» + ç”Ÿæˆåˆ†æï¼‰----------
def analyze_curve(image):
    # 3.1 åˆ†ç±»
    pred, pred_idx, probs = learn.predict(image)
    curve_type = str(pred)
    confidence = probs[pred_idx].item()

    # æ ¼å¼åŒ–åˆ†ç±»ç»“æœ
    classification_result = {learn.dls.vocab[i]: float(probs[i]) for i in range(len(probs))}

    # 3.2 æ„é€ æç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€ä½ç”µæ± ææ–™ç§‘å­¦å®¶ã€‚ç”¨æˆ·ä¸Šä¼ äº†ä¸€å¼ ç”µæ± æ›²çº¿å›¾ï¼Œç»æ¨¡å‹è¯†åˆ«ä¸º **{curve_type}** ç±»å‹ï¼ˆç½®ä¿¡åº¦ {confidence:.2%}ï¼‰ã€‚
è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š
1. è¿™ç§æ›²çº¿é€šå¸¸ç”¨æ¥è¡¡é‡ç”µæ± çš„ä»€ä¹ˆæ€§èƒ½ï¼Ÿ
2. å®éªŒç»„å’Œå¯¹ç…§ç»„æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

å›ç­”ï¼š"""

    # 3.3 è°ƒç”¨ Qwen ç”Ÿæˆå›ç­”
    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=256,
            do_sample=True,
            temperature=0.7,
            top_p=0.9
        )
    answer = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)

    # 3.4 è¿”å›ç»“æœï¼ˆåˆ†ç±»ç»“æœ + ç”Ÿæˆåˆ†æï¼‰
    return classification_result, answer

# ---------- 4. åˆ›å»º Gradio ç•Œé¢ ----------
with gr.Blocks(title="ç”µæ± æ›²çº¿æ™ºèƒ½åˆ†æç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ”‹ ç”µæ± æ›²çº¿æ™ºèƒ½åˆ†æç³»ç»Ÿ
    ä¸Šä¼ ä¸€å¼ é”‚ç”µæ± æ›²çº¿å›¾ï¼ˆè¿‡ç”µä½ã€å¯¹ç§°ç”µæ± æˆ–å…¨ç”µæ± ï¼‰ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨è¯†åˆ«å…¶ç±»åˆ«ï¼Œå¹¶ç”Ÿæˆä¸“ä¸šçš„æ–‡å­—åˆ†æã€‚
    """)

    with gr.Row():
        with gr.Column(scale=1):
            image_input = gr.Image(type="pil", label="ä¸Šä¼ æ›²çº¿å›¾")
            submit_btn = gr.Button("å¼€å§‹åˆ†æ", variant="primary")

        with gr.Column(scale=1):
            label_output = gr.Label(num_top_classes=3, label="åˆ†ç±»ç»“æœ")
            text_output = gr.Textbox(label="æ™ºèƒ½åˆ†æ", lines=10, placeholder="ç­‰å¾…åˆ†æç»“æœ...")

    submit_btn.click(
        fn=analyze_curve,
        inputs=image_input,
        outputs=[label_output, text_output]
    )

    gr.Markdown("### ğŸ“Œ ç¤ºä¾‹å›¾ç‰‡")
    gr.Examples(
        examples=[
            ["data/overpotential/ä½ çš„ç¤ºä¾‹å›¾ç‰‡1.png"],
            ["data/symmetrical/ä½ çš„ç¤ºä¾‹å›¾ç‰‡2.png"],
            ["data/full_cell/ä½ çš„ç¤ºä¾‹å›¾ç‰‡3.png"],
        ],
        inputs=image_input,
        outputs=[label_output, text_output],
        fn=analyze_curve,
        cache_examples=False
    )

# ---------- 5. å¯åŠ¨åº”ç”¨ ----------
if __name__ == "__main__":
    demo.launch(share=False)
